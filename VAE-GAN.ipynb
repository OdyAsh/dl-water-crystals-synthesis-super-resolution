{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import os,cv2\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from torchvision.utils import make_grid \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class waterCrtystals(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.root = root\n",
    "        self.transform=transform\n",
    "    def __len__(self):\n",
    "        return len([entry for entry in os.listdir(self.root) if os.path.isfile(os.path.join(self.root, entry))])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        for i, img in enumerate(os.listdir(self.root)):\n",
    "            img = cv2.imread(os.path.join(f'{self.root}/{img}'))\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            if i == idx:\n",
    "                return img\n",
    "\n",
    "\n",
    "def dataloader(batch_size):\n",
    "  dataroot=\"dataset/Microparticle\"\n",
    "  transform=transforms.Compose([transforms.ToTensor(), transforms.Resize(128),transforms.CenterCrop(128),transforms.Normalize((0),(1))])\n",
    "  dataset=waterCrtystals(root=dataroot,transform=transform)\n",
    "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "  return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Encoder,self).__init__()\n",
    "    self.conv1=nn.Conv2d(3,64,5,padding=2,stride=2)   #in_channels=3\n",
    "    self.bn1=nn.BatchNorm2d(64,momentum=0.9)\n",
    "    self.conv2=nn.Conv2d(64,128,5,padding=2,stride=2)\n",
    "    self.bn2=nn.BatchNorm2d(128,momentum=0.9)\n",
    "    self.conv3=nn.Conv2d(128,256,5,padding=2,stride=2)\n",
    "    self.bn3=nn.BatchNorm2d(256,momentum=0.9)\n",
    "    self.relu=nn.LeakyReLU(0.2)\n",
    "    self.fc1=nn.Linear(256*16*16,2048)\n",
    "    self.bn4=nn.BatchNorm1d(2048,momentum=0.9)\n",
    "    self.fc_mean=nn.Linear(2048,128)\n",
    "    self.fc_logvar=nn.Linear(2048,128)   #latent dim=128\n",
    "  \n",
    "  def forward(self,x):\n",
    "    batch_size=x.size()[0]\n",
    "    out=self.relu(self.bn1(self.conv1(x)))\n",
    "    out=self.relu(self.bn2(self.conv2(out)))\n",
    "    out=self.relu(self.bn3(self.conv3(out)))\n",
    "    out=out.view(batch_size,-1)\n",
    "    out=self.relu(self.bn4(self.fc1(out)))\n",
    "    mean=self.fc_mean(out)\n",
    "    logvar=self.fc_logvar(out)\n",
    "    \n",
    "    return mean,logvar\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Decoder,self).__init__()\n",
    "    self.fc1=nn.Linear(128,16*16*256)\n",
    "    self.bn1=nn.BatchNorm1d(16*16*256,momentum=0.9)\n",
    "    self.relu=nn.LeakyReLU(0.2)\n",
    "    self.deconv1=nn.ConvTranspose2d(256,256,6, stride=2, padding=2)\n",
    "    self.bn2=nn.BatchNorm2d(256,momentum=0.9)\n",
    "    self.deconv2=nn.ConvTranspose2d(256,128,6, stride=2, padding=2)\n",
    "    self.bn3=nn.BatchNorm2d(128,momentum=0.9)\n",
    "    self.deconv3=nn.ConvTranspose2d(128,32,6, stride=2, padding=2)\n",
    "    self.bn4=nn.BatchNorm2d(32,momentum=0.9)\n",
    "    self.deconv4=nn.ConvTranspose2d(32,3,5, stride=1, padding=2)\n",
    "    self.tanh=nn.Tanh()\n",
    "\n",
    "  def forward(self,x):\n",
    "    batch_size=x.size()[0]\n",
    "    x=self.relu(self.bn1(self.fc1(x)))\n",
    "    x=x.view(-1,256,16,16)\n",
    "    x=self.relu(self.bn2(self.deconv1(x)))\n",
    "    x=self.relu(self.bn3(self.deconv2(x)))\n",
    "    x=self.relu(self.bn4(self.deconv3(x)))\n",
    "    x=self.tanh(self.deconv4(x))\n",
    "    return x\n",
    "  \n",
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Discriminator,self).__init__()\n",
    "    self.conv1=nn.Conv2d(3,32,5,padding=2,stride=1)\n",
    "    self.relu=nn.LeakyReLU(0.2)\n",
    "    self.conv2=nn.Conv2d(32,128,5,padding=2,stride=2)\n",
    "    self.bn1=nn.BatchNorm2d(128,momentum=0.9)\n",
    "    self.conv3=nn.Conv2d(128,256,5,padding=2,stride=2)\n",
    "    self.bn2=nn.BatchNorm2d(256,momentum=0.9)\n",
    "    self.conv4=nn.Conv2d(256,256,5,padding=2,stride=2)\n",
    "    self.bn3=nn.BatchNorm2d(256,momentum=0.9)\n",
    "    self.fc1=nn.Linear(16*16*256,512)\n",
    "    self.bn4=nn.BatchNorm1d(512,momentum=0.9)\n",
    "    self.fc2=nn.Linear(512,1)\n",
    "    self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "  def forward(self,x):\n",
    "    batch_size=x.size()[0]\n",
    "    x=self.relu(self.conv1(x))\n",
    "    x=self.relu(self.bn1(self.conv2(x)))\n",
    "    x=self.relu(self.bn2(self.conv3(x)))\n",
    "    x=self.relu(self.bn3(self.conv4(x)))\n",
    "    x=x.view(-1,256*16*16)\n",
    "    x1=x;\n",
    "    x=self.relu(self.bn4(self.fc1(x)))\n",
    "    x=self.sigmoid(self.fc2(x))\n",
    "\n",
    "    return x,x1\n",
    "class VAE_GAN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(VAE_GAN,self).__init__()\n",
    "    self.encoder=Encoder()\n",
    "    self.decoder=Decoder()\n",
    "    self.discriminator=Discriminator()\n",
    "    self.encoder.apply(weights_init)\n",
    "    self.decoder.apply(weights_init)\n",
    "    self.discriminator.apply(weights_init)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    bs=x.size()[0]\n",
    "    z_mean,z_logvar=self.encoder(x)\n",
    "    std = z_logvar.mul(0.5).exp_()\n",
    "        \n",
    "    #sampling epsilon from normal distribution\n",
    "    epsilon=Variable(torch.randn(bs,128)).to(device)\n",
    "    z=z_mean+std*epsilon\n",
    "    x_tilda=self.decoder(z)\n",
    "      \n",
    "    return z_mean,z_logvar,x_tilda\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid , save_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def show_and_save(file_name,img):\n",
    "    npimg = np.transpose(img.numpy(),(1,2,0))\n",
    "    f = \"generated/%s.png\" % file_name\n",
    "    fig = plt.figure(dpi=200)\n",
    "    fig.suptitle(file_name, fontsize=14, fontweight='bold')\n",
    "    #plt.imshow(npimg)\n",
    "    plt.imsave(f,npimg)\n",
    "def plot_loss(loss_list):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Loss During Training\")\n",
    "    plt.plot(loss_list,label=\"Loss\")\n",
    "    \n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=dataloader(30)\n",
    "gen=VAE_GAN().to(device)\n",
    "discrim=Discriminator().to(device)\n",
    "real_batch = next(iter(data_loader))\n",
    "show_and_save(\"training\" ,make_grid((real_batch[0]*0.5+0.5).cpu(),8))\n",
    "\n",
    "epochs=100\n",
    "lr=3e-4\n",
    "alpha=0.1\n",
    "gamma=15\n",
    "\n",
    "criterion=nn.BCELoss().to(device)\n",
    "optim_E=torch.optim.RMSprop(gen.encoder.parameters(), lr=lr)\n",
    "optim_D=torch.optim.RMSprop(gen.decoder.parameters(), lr=lr)\n",
    "optim_Dis=torch.optim.RMSprop(discrim.parameters(), lr=lr*alpha)\n",
    "z_fixed=Variable(torch.randn((64,128))).to(device)\n",
    "x_fixed=Variable(real_batch[0]).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  prior_loss_list,gan_loss_list,recon_loss_list=[],[],[]\n",
    "  dis_real_list,dis_fake_list,dis_prior_list=[],[],[]\n",
    "  for i, (data) in enumerate(data_loader, 0):\n",
    "    bs=data.size()[0]   #the output will be same size of the batch\n",
    "    \n",
    "    ones_label=Variable(torch.ones(bs,1)).to(device)\n",
    "    zeros_label=Variable(torch.zeros(bs,1)).to(device)\n",
    "    zeros_label1=Variable(torch.zeros(100,1)).to(device)\n",
    "    datav = Variable(data).to(device)\n",
    "    print(datav.shape)\n",
    "    mean, logvar, rec_enc = gen(datav)\n",
    "    z_p = Variable(torch.randn(100,128)).to(device)\n",
    "    x_p_tilda = gen.decoder(z_p)\n",
    " \n",
    "    output = discrim(datav)[0]\n",
    "    errD_real = criterion(output, ones_label)\n",
    "    dis_real_list.append(errD_real.item())\n",
    "    output = discrim(rec_enc)[0]\n",
    "    errD_rec_enc = criterion(output, zeros_label)\n",
    "    dis_fake_list.append(errD_rec_enc.item())\n",
    "    output = discrim(x_p_tilda)[0]\n",
    "    errD_rec_noise = criterion(output, zeros_label1)\n",
    "    dis_prior_list.append(errD_rec_noise.item())\n",
    "    gan_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
    "    gan_loss_list.append(gan_loss.item())\n",
    "    optim_Dis.zero_grad()\n",
    "    gan_loss.backward(retain_graph=True)\n",
    "    optim_Dis.step()\n",
    "\n",
    "\n",
    "    output = discrim(datav)[0]\n",
    "    errD_real = criterion(output, ones_label)\n",
    "    output = discrim(rec_enc)[0]\n",
    "    errD_rec_enc = criterion(output, zeros_label)\n",
    "    output = discrim(x_p_tilda)[0]\n",
    "    errD_rec_noise = criterion(output, zeros_label1)\n",
    "    gan_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
    "    \n",
    "\n",
    "    x_l_tilda = discrim(rec_enc)[1]\n",
    "    x_l = discrim(datav)[1]\n",
    "    rec_loss = ((x_l_tilda - x_l) ** 2).mean()\n",
    "    err_dec = gamma * rec_loss - gan_loss \n",
    "    recon_loss_list.append(rec_loss.item())\n",
    "    optim_D.zero_grad()\n",
    "    err_dec.backward(retain_graph=True)\n",
    "    optim_D.step()\n",
    "    \n",
    "    mean, logvar, rec_enc = gen(datav)\n",
    "    x_l_tilda = discrim(rec_enc)[1]\n",
    "    x_l = discrim(datav)[1]\n",
    "    rec_loss = ((x_l_tilda - x_l) ** 2).mean()\n",
    "    prior_loss = 1 + logvar - mean.pow(2) - logvar.exp()\n",
    "    prior_loss = (-0.5 * torch.sum(prior_loss))/torch.numel(mean.data)\n",
    "    prior_loss_list.append(prior_loss.item())\n",
    "    err_enc = prior_loss + 5*rec_loss\n",
    "\n",
    "    optim_E.zero_grad()\n",
    "    err_enc.backward(retain_graph=True)\n",
    "    optim_E.step()\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_gan: %.4f\\tLoss_prior: %.4f\\tRec_loss: %.4f\\tdis_real_loss: %0.4f\\tdis_fake_loss: %.4f\\tdis_prior_loss: %.4f'\n",
    "                  % (epoch,epochs, i, len(data_loader),\n",
    "                     gan_loss.item(), prior_loss.item(),rec_loss.item(),errD_real.item(),errD_rec_enc.item(),errD_rec_noise.item()))\n",
    "\n",
    "  b=gen(x_fixed)[2]\n",
    "  b=b.detach()\n",
    "  c=gen.decoder(z_fixed)\n",
    "  c=c.detach()\n",
    "  \n",
    "  \n",
    "  #if epoch%10 == 0:    \n",
    "  show_and_save('noise_epoch_%d.png' % epoch ,make_grid((c*0.5+0.5).cpu(),8))\n",
    "  show_and_save('epoch_%d.png' % epoch ,make_grid((b*0.5+0.5).cpu(),8))\n",
    "\n",
    "plot_loss(prior_loss_list)\n",
    "plot_loss(recon_loss_list)\n",
    "plot_loss(gan_loss_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
