{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VkYndUjA16D-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "import os,cv2\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "from torchvision.utils import make_grid \n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets.mnist import load_data\n",
        "from skimage.transform import resize\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "runningFromColab = False\n",
        "if 'CGROUP_MEMORY_EVENTS' in os.environ and 'colab' in os.environ['CGROUP_MEMORY_EVENTS']:\n",
        "  runningFromColab = True\n",
        "if runningFromColab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "if runningFromColab:\n",
        "  %cd /content/drive/MyDrive/WaterCrystal/final_project/dl-water-crystals-synthesis-super-resolution"
      ],
      "metadata": {
        "id": "55qAy8J12S4b",
        "outputId": "659fefd4-9104-4fed-ceed-f006a2ca0895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/WaterCrystal/final_project/dl-water-crystals-synthesis-super-resolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if runningFromColab:\n",
        "  !pip install huggingface-hub\n",
        "  !pip install datasets\n",
        "  !pip install diffusers[training]==0.11.1\n",
        "  !pip install accelerate\n",
        "  !pip install Augmentor\n",
        "  # install Git-LFS to upload the model checkpoints\n",
        "  !sudo apt -qq install git-lfs\n",
        "  !git config --global credential.helper store"
      ],
      "metadata": {
        "id": "pUwtC0dR2jJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9J1kk1Cq16EC"
      },
      "outputs": [],
      "source": [
        "class waterCrtystals(Dataset):\n",
        "    def __init__(self, root, transform):\n",
        "        self.root = root\n",
        "        self.transform=transform\n",
        "    def __len__(self):\n",
        "        return len([entry for entry in os.listdir(self.root) if os.path.isfile(os.path.join(self.root, entry))])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        for i, img in enumerate(os.listdir(self.root)):\n",
        "            img = cv2.imread(os.path.join(f'{self.root}/{img}'))\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            if i == idx:\n",
        "                return img,idx\n",
        "\n",
        "\n",
        "def dataloader(batch_size):\n",
        "  dataroot=\"dataset/Microparticle\"\n",
        "  transform=transforms.Compose([transforms.ToTensor(), transforms.Resize(128),transforms.CenterCrop(128),transforms.Normalize((0),(1))])\n",
        "  dataset=waterCrtystals(root=dataroot,transform=transform)\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "  return data_loader\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xwMOEm7y16EE"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.conv1=nn.Conv2d(3,64,5,padding=2,stride=2)   #in_channels=3\n",
        "    self.bn1=nn.BatchNorm2d(64,momentum=0.9)\n",
        "    self.conv2=nn.Conv2d(64,128,5,padding=2,stride=2)\n",
        "    self.bn2=nn.BatchNorm2d(128,momentum=0.9)\n",
        "    self.conv3=nn.Conv2d(128,256,5,padding=2,stride=2)\n",
        "    self.bn3=nn.BatchNorm2d(256,momentum=0.9)\n",
        "    self.relu=nn.LeakyReLU(0.2)\n",
        "    self.fc1=nn.Linear(256*16*16,2048)\n",
        "    self.bn4=nn.BatchNorm1d(2048,momentum=0.9)\n",
        "    self.fc_mean=nn.Linear(2048,128)\n",
        "    self.fc_logvar=nn.Linear(2048,128)   #latent dim=128\n",
        "  \n",
        "  def forward(self,x):\n",
        "    batch_size=x.size()[0]\n",
        "    out=self.relu(self.bn1(self.conv1(x)))\n",
        "    out=self.relu(self.bn2(self.conv2(out)))\n",
        "    out=self.relu(self.bn3(self.conv3(out)))\n",
        "    out=out.view(batch_size,-1)\n",
        "    out=self.relu(self.bn4(self.fc1(out)))\n",
        "    mean=self.fc_mean(out)\n",
        "    logvar=self.fc_logvar(out)\n",
        "    \n",
        "    return mean,logvar\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.fc1=nn.Linear(128,16*16*256)\n",
        "    self.bn1=nn.BatchNorm1d(16*16*256,momentum=0.9)\n",
        "    self.relu=nn.LeakyReLU(0.2)\n",
        "    self.deconv1=nn.ConvTranspose2d(256,256,6, stride=2, padding=2)\n",
        "    self.bn2=nn.BatchNorm2d(256,momentum=0.9)\n",
        "    self.deconv2=nn.ConvTranspose2d(256,128,6, stride=2, padding=2)\n",
        "    self.bn3=nn.BatchNorm2d(128,momentum=0.9)\n",
        "    self.deconv3=nn.ConvTranspose2d(128,32,6, stride=2, padding=2)\n",
        "    self.bn4=nn.BatchNorm2d(32,momentum=0.9)\n",
        "    self.deconv4=nn.ConvTranspose2d(32,3,5, stride=1, padding=2)\n",
        "    self.tanh=nn.Tanh()\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch_size=x.size()[0]\n",
        "    x=self.relu(self.bn1(self.fc1(x)))\n",
        "    x=x.view(-1,256,16,16)\n",
        "    x=self.relu(self.bn2(self.deconv1(x)))\n",
        "    x=self.relu(self.bn3(self.deconv2(x)))\n",
        "    x=self.relu(self.bn4(self.deconv3(x)))\n",
        "    x=self.tanh(self.deconv4(x))\n",
        "    return x\n",
        "  \n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator,self).__init__()\n",
        "    self.conv1=nn.Conv2d(3,32,5,padding=2,stride=1)\n",
        "    self.relu=nn.LeakyReLU(0.2)\n",
        "    self.conv2=nn.Conv2d(32,128,5,padding=2,stride=2)\n",
        "    self.bn1=nn.BatchNorm2d(128,momentum=0.9)\n",
        "    self.conv3=nn.Conv2d(128,256,5,padding=2,stride=2)\n",
        "    self.bn2=nn.BatchNorm2d(256,momentum=0.9)\n",
        "    self.conv4=nn.Conv2d(256,256,5,padding=2,stride=2)\n",
        "    self.bn3=nn.BatchNorm2d(256,momentum=0.9)\n",
        "    self.fc1=nn.Linear(16*16*256,512)\n",
        "    self.bn4=nn.BatchNorm1d(512,momentum=0.9)\n",
        "    self.fc2=nn.Linear(512,1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch_size=x.size()[0]\n",
        "    x=self.relu(self.conv1(x))\n",
        "    x=self.relu(self.bn1(self.conv2(x)))\n",
        "    x=self.relu(self.bn2(self.conv3(x)))\n",
        "    x=self.relu(self.bn3(self.conv4(x)))\n",
        "    x=x.view(-1,256*16*16)\n",
        "    x1=x;\n",
        "    x=self.relu(self.bn4(self.fc1(x)))\n",
        "    x=self.sigmoid(self.fc2(x))\n",
        "\n",
        "    return x,x1\n",
        "class VAE_GAN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VAE_GAN,self).__init__()\n",
        "    self.encoder=Encoder()\n",
        "    self.decoder=Decoder()\n",
        "    self.discriminator=Discriminator()\n",
        "    self.encoder.apply(weights_init)\n",
        "    self.decoder.apply(weights_init)\n",
        "    self.discriminator.apply(weights_init)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    bs=x.size()[0]\n",
        "    z_mean,z_logvar=self.encoder(x)\n",
        "    std = z_logvar.mul(0.5).exp_()\n",
        "        \n",
        "    #sampling epsilon from normal distribution\n",
        "    epsilon=Variable(torch.randn(bs,128)).to(device)\n",
        "    z=z_mean+std*epsilon\n",
        "    x_tilda=self.decoder(z)\n",
        "      \n",
        "    return z_mean,z_logvar,x_tilda\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fMfmseD416EG"
      },
      "outputs": [],
      "source": [
        "def show_and_save(file_name,img):\n",
        "    npimg = np.transpose(img.numpy(),(1,2,0))\n",
        "    f = \"generated-VAEGANs/%s.png\" % file_name\n",
        "    fig = plt.figure(dpi=200)\n",
        "    fig.suptitle(file_name, fontsize=14, fontweight='bold')\n",
        "    #plt.imshow(npimg)\n",
        "    plt.imsave(f,npimg)\n",
        "def plot_loss(loss_list):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Loss During Training\")\n",
        "    plt.plot(loss_list,label=\"Loss\")\n",
        "    \n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YBpjgTcX16EI"
      },
      "outputs": [],
      "source": [
        "# scale an array of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        " images_list = list()\n",
        " for image in images:\n",
        "       # resize with nearest neighbor interpolation\n",
        "       new_image = resize(image, new_shape, 0)\n",
        "       # store\n",
        "       images_list.append(new_image)\n",
        " return asarray(images_list)\n",
        " \n",
        "# calculate frechet inception distance\n",
        "def calculate_fid(model, images1, images2):\n",
        " # calculate activations\n",
        " act1 = model.predict(images1)\n",
        " act2 = model.predict(images2)\n",
        " # calculate mean and covariance statistics\n",
        " mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        " mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        " # calculate sum squared difference between means\n",
        " ssdiff = np.sum((mu1 - mu2)**2.0)\n",
        " # calculate sqrt of product between cov\n",
        " covmean = sqrtm(sigma1.dot(sigma2))\n",
        " # check and correct imaginary numbers from sqrt\n",
        " if iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        " # calculate score\n",
        " fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        " return fid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xdofsrU616EI",
        "outputId": "f5f29b6c-9d74-4198-c458-b4296c407d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n",
            "Prepared (10, 32, 32, 3) (10, 32, 32, 3)\n",
            "Scaled (10, 128, 128, 3) (10, 128, 128, 3)\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 1s 945ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d0a1859dd8b4>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimages2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# fid between images1 and images1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FID (same): %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# fid between images1 and images2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c4e1eba37e5e>\u001b[0m in \u001b[0;36mcalculate_fid\u001b[0;34m(model, images1, images2)\u001b[0m\n\u001b[1;32m     20\u001b[0m  \u001b[0mssdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m  \u001b[0;31m# calculate sqrt of product between cov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m  \u001b[0mcovmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m  \u001b[0;31m# check and correct imaginary numbers from sqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0miscomplexobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36msqrtm\u001b[0;34m(A, disp, blocksize)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mkeep_it_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misrealobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeep_it_real\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrsf2csf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/linalg/_decomp_schur.py\u001b[0m in \u001b[0;36mschur\u001b[0;34m(a, output, lwork, overwrite_a, sort, check_finite)\u001b[0m\n\u001b[1;32m    157\u001b[0m                              \"callable, or one of ('lhp','rhp','iuc','ouc')\")\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     result = gees(sfunction, a1, lwork=lwork, overwrite_a=overwrite_a,\n\u001b[0m\u001b[1;32m    160\u001b[0m                   sort_t=sort_t)\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#TEST\n",
        "\n",
        "# prepare the inception v3 model\n",
        "model = InceptionV3(include_top=False, pooling='avg', input_shape=(128,128,3))\n",
        "# define two fake collections of images\n",
        "images1 = randint(0, 255, 10*32*32*3)\n",
        "images1 = images1.reshape((10,32,32,3))\n",
        "images2 = randint(0, 255, 10*32*32*3)\n",
        "images2 = images2.reshape((10,32,32,3))\n",
        "print('Prepared', images1.shape, images2.shape)\n",
        "# convert integer to floating point values\n",
        "images1 = images1.astype('float32')\n",
        "images2 = images2.astype('float32')\n",
        "# resize images\n",
        "images1 = scale_images(images1, (128,128,3))\n",
        "images2 = scale_images(images2, (128,128,3))\n",
        "print('Scaled', images1.shape, images2.shape)\n",
        "# pre-process images\n",
        "images1 = preprocess_input(images1)\n",
        "images2 = preprocess_input(images2)\n",
        "# fid between images1 and images1\n",
        "fid = calculate_fid(model, images1, images1)\n",
        "print('FID (same): %.3f' % fid)\n",
        "# fid between images1 and images2\n",
        "fid = calculate_fid(model, images1, images2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2hozXPM16EL"
      },
      "outputs": [],
      "source": [
        "model = InceptionV3(include_top=False, pooling='avg', input_shape=(128,128,3))\n",
        "data_loader=dataloader(20)\n",
        "gen=VAE_GAN().to(device)\n",
        "discrim=Discriminator().to(device)\n",
        "real_batch = next(iter(data_loader))\n",
        "show_and_save(\"training\" ,make_grid((real_batch[0]*0.5+0.5).cpu(),8))\n",
        "epochs=100\n",
        "lr=3e-4\n",
        "alpha=0.1\n",
        "gamma=15\n",
        "\n",
        "criterion=nn.BCELoss().to(device)\n",
        "optim_E=torch.optim.RMSprop(gen.encoder.parameters(), lr=lr)\n",
        "optim_D=torch.optim.RMSprop(gen.decoder.parameters(), lr=lr)\n",
        "optim_Dis=torch.optim.RMSprop(discrim.parameters(), lr=lr*alpha)\n",
        "z_fixed=Variable(torch.randn((64,128))).to(device)\n",
        "x_fixed=Variable(real_batch[0]).to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  prior_loss_list,gan_loss_list,recon_loss_list=[],[],[]\n",
        "  dis_real_list,dis_fake_list,dis_prior_list=[],[],[]\n",
        "  fid_scores=[]\n",
        "  for i, (data,_) in enumerate(data_loader, 0):\n",
        "    bs=data.size()[0]\n",
        "    \n",
        "    ones_label=Variable(torch.ones(bs,1)).to(device)\n",
        "    zeros_label=Variable(torch.zeros(bs,1)).to(device)\n",
        "    zeros_label1=Variable(torch.zeros(10,1)).to(device)\n",
        "    datav = Variable(data).to(device)\n",
        "    mean, logvar, rec_enc = gen(datav)\n",
        "    z_p = Variable(torch.randn(10,128)).to(device)\n",
        "    x_p_tilda = gen.decoder(z_p)\n",
        " \n",
        "    output = discrim(datav)[0]\n",
        "    errD_real = criterion(output, ones_label)\n",
        "    dis_real_list.append(errD_real.item())\n",
        "    output = discrim(rec_enc)[0]\n",
        "    errD_rec_enc = criterion(output, zeros_label)\n",
        "    dis_fake_list.append(errD_rec_enc.item())\n",
        "    output = discrim(x_p_tilda)[0]\n",
        "    errD_rec_noise = criterion(output, zeros_label1)\n",
        "    dis_prior_list.append(errD_rec_noise.item())\n",
        "    gan_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
        "    gan_loss_list.append(gan_loss.item())\n",
        "    optim_Dis.zero_grad()\n",
        "    gan_loss.backward(retain_graph=True)\n",
        "    optim_Dis.step()\n",
        "\n",
        "\n",
        "    output = discrim(datav)[0]\n",
        "    errD_real = criterion(output, ones_label)\n",
        "    output = discrim(rec_enc)[0]\n",
        "    errD_rec_enc = criterion(output, zeros_label)\n",
        "    output = discrim(x_p_tilda)[0]\n",
        "    errD_rec_noise = criterion(output, zeros_label1)\n",
        "    gan_loss = errD_real + errD_rec_enc + errD_rec_noise\n",
        "    \n",
        "\n",
        "    x_l_tilda = discrim(rec_enc)[1]\n",
        "    x_l = discrim(datav)[1]\n",
        "    rec_loss = ((x_l_tilda - x_l) ** 2).mean()\n",
        "    err_dec = gamma * rec_loss - gan_loss \n",
        "    recon_loss_list.append(rec_loss.item())\n",
        "    optim_D.zero_grad()\n",
        "    err_dec.backward(retain_graph=True)\n",
        "    optim_D.step()\n",
        "    \n",
        "    mean, logvar, rec_enc = gen(datav)\n",
        "    x_l_tilda = discrim(rec_enc)[1]\n",
        "    x_l = discrim(datav)[1]\n",
        "    rec_loss = ((x_l_tilda - x_l) ** 2).mean()\n",
        "    prior_loss = 1 + logvar - mean.pow(2) - logvar.exp()\n",
        "    prior_loss = (-0.5 * torch.sum(prior_loss))/torch.numel(mean.data)\n",
        "    prior_loss_list.append(prior_loss.item())\n",
        "    err_enc = prior_loss + 5*rec_loss\n",
        "\n",
        "    b=gen(x_fixed)[2]\n",
        "    b=b.detach()\n",
        "    c=gen.decoder(z_fixed)\n",
        "    c=c.detach()\n",
        "\n",
        "    real = scale_images(data, (128,128,3))\n",
        "    fake = scale_images(b, (128,128,3))\n",
        "    fid_score = calculate_fid(model, real, fake)\n",
        "    fid_scores.append(fid_score)\n",
        "    \n",
        "    optim_E.zero_grad()\n",
        "    err_enc.backward(retain_graph=True)\n",
        "    optim_E.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_gan: %.4f\\tLoss_prior: %.4f\\tRec_loss: %.4f\\tdis_real_loss: %0.4f\\tdis_fake_loss: %.4f\\tdis_prior_loss: %.4f\\tFID: %.4f'\n",
        "                  % (epoch,epochs, i, len(data_loader),\n",
        "                     gan_loss.item(), prior_loss.item(),rec_loss.item(),errD_real.item(),errD_rec_enc.item(),errD_rec_noise.item(), fid_score))\n",
        "\n",
        "\n",
        "  show_and_save('noise_epoch_%d.png' % epoch ,make_grid((c*0.5+0.5).cpu(),8))\n",
        "  show_and_save('epoch_%d.png' % epoch ,make_grid((b*0.5+0.5).cpu(),8))\n",
        "  \n",
        "plot_loss(prior_loss_list)\n",
        "plot_loss(recon_loss_list)\n",
        "plot_loss(gan_loss_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5KxLJ4eL2tWS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}